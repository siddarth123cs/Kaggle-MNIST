{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "test = pd.read_csv('test (2).csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAFXCAYAAABOYlxEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x259e1f6ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# free some space\n",
    "del train \n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2\n",
    "\n",
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, stratify = Y_train, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFJCAYAAAASfw+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEbNJREFUeJzt3X9M1IUfx/HXcUAkN7/MZFOHIqauKTnniFYOa22EWopu\nODUGBczU2ZRMFAnTgqGb9hdJLudWKaXMrY1aWdPlaEH+4UIHTPsxc2r+gJbTIxGEz/cvKX+Eb877\ncIc9H38Jvvvc+3bt6ee4+3Aex3EcAQD6FBHqBQBgMCCWAGBALAHAgFgCgAGxBACDSLdvoKOjQ01N\nTYqPj5fX63X75gAgIN3d3WptbVVycrJiYmLu+HvXY9nU1KTs7Gy3bwYAgqK6ulopKSl3fN/1WMbH\nx/cuMGLECLdvDgACcuHCBWVnZ/c263YBxbKnp0ebNm3SyZMnFR0drfLyciUmJt519uZT7xEjRigh\nISGQmwOAAfNvPy4M6AWegwcPqrOzU/v27dMbb7yhLVu23NdyABDuAorl0aNHlZaWJkmaOnWqmpqa\ngroUAISbgGLp9/vl8/l6v/Z6vbpx40bQlgKAcBNQLH0+n9rb23u/7unpUWSk668VAUDIBBTLadOm\nqa6uTpLU2NioiRMnBnUpAAg3AZ0Opqen6/vvv9eiRYvkOI4qKiqCvRcAhJWAYhkREaF33nkn2LsA\nQNji2nAAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAAD\nYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHA\ngFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsA\nMCCWAGBALAHAgFgCgAGxBACDyED/w/nz58vn80mSEhIStHnz5qAtBQDhJqBYXr9+XY7jaPfu3cHe\nBwDCUkBPw0+cOKFr164pPz9fubm5amxsDPZeABBWAjqzjImJUUFBgRYsWKDffvtNS5Ys0YEDBxQZ\nGfCzegAIawHVLSkpSYmJifJ4PEpKSlJcXJxaW1s1cuTIYO8HAGEhoKfh+/fv15YtWyRJFy9elN/v\nV3x8fFAXA4BwEtCZZVZWltavX6/FixfL4/GooqKCp+AAHmgBFS46OlrvvvtusHcBgLDFm9IBwIDn\nzhiUGhoazLOvvPKKefbnn382zf3vf/8zH/PVV181z65atco8O2rUKPMs7h9nlgBgQCwBwIBYAoAB\nsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIDLHeG6K1eumGdLS0tNczt37jQf8/r16+ZZj8dj\nmuvPfdq2bZt5trKy0jzb1tZmmhsyZIj5mPh3nFkCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBA\nLAHAgFgCgAFX8CAgly5dMs+mpaWZZ3/55ZdA1gma9PR001x/Pizso48+Ms/252qjWbNmmeYOHjxo\nPmZUVJR59r+GM0sAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGDA5Y4ISH8+\nWMuNSxhjYmLMs1VVVebZnJwc01xHR4f5mP2Z3bdvn3n2u+++M83duHHDfEwud/x3nFkCgAGxBAAD\nYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADLnfELT7++GPT3LZt21y5/aeeeso0V1NT\nYz5mfz6J0WrIkCHm2Q8//NA829DQYJ51HMc05/V6zcfEv+PMEgAMTLE8duxY7y8YOH36tBYvXqyX\nXnpJGzduVE9Pj6sLAkA4uGcsd+7cqdLS0t4Pf9+8ebMKCwv1ySefyHEcHTp0yPUlASDU7hnLMWPG\n3PLruJqbm5WamipJmjFjhurr693bDgDCxD1jmZGRocjIv18HchxHHo9HkhQbG6urV6+6tx0AhIl+\nv8ATEfH3f9Le3q6hQ4cGdSEACEf9juWkSZN05MgRSVJdXZ1SUlKCvhQAhJt+x3LdunWqrKzUwoUL\n1dXVpYyMDDf2AoCwYnpTekJCQu+bgJOSkrRnzx5XlwKAcMMVPP8B/XkR7uWXXzbN3XyRz8Ln85ln\n33//fdOcG1fl9MeZM2fMs++99555dsWKFebZNWvWmGdx/7iCBwAMiCUAGBBLADAglgBgQCwBwIBY\nAoABsQQAA2IJAAbEEgAMiCUAGHC54yDVn4/zyMvLM89aL2Psz+WO/bn9xx9/3Dzrhrq6OtPcCy+8\nYD7mX3/9Feg6fZo+fbppzvohcOgbZ5YAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwIJYA\nYEAsAcCAyx0HqevXr5tnP/vsMxc3ubeioqKgH7M/97+6uto8u2zZMtNcd3e3+ZhuSUxMDPUK/ymc\nWQKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKAAVfwwHVnz541z3Z2dprmVq9ebT5m\nbW2tebY/H8RmFRFhPydZsmSJeXbUqFGBrIMAcWYJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoAB\nsQQAA2IJAAbEEgAMuNxxkIqOjjbPPvfcc+bZQ4cOBbJOn6ZPnx70Yw4mjzzyiHm2qqrKxU1wPziz\nBAADUyyPHTumnJwcSVJLS4vS0tKUk5OjnJwcffnll64uCADh4J5Pw3fu3Kna2lo9/PDDkqTm5mbl\n5eUpPz/f9eUAIFzc88xyzJgxqqys7P26qalJhw8fVnZ2tkpKSuT3+11dEADCwT1jmZGRocjIv09A\np0yZorVr16q6ulqjR4/W9u3bXV0QAMJBv1/gSU9PV3Jycu+fW1pagr4UAISbfseyoKBAx48flyQ1\nNDRo8uTJQV8KAMJNv99nuWnTJpWVlSkqKkrDhw9XWVmZG3sBQFgxxTIhIUE1NTWSpMmTJ2vv3r2u\nLgUA4YY3pQOAAZc7DlJer9c8m5mZaZ49ePBgIOuENcdxQnr7s2bNCuntIzg4swQAA2IJAAbEEgAM\niCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAZc7vgf8Nprr5lnu7q6THPFxcXmY964ccM8+8QT\nT5jmfv31V/Mx//jjD/Osx+Mxzd38mBULfjPXg4EzSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIA\nDIglABgQSwAw4Aoe3OL11183zeXl5ZmP2dPTY55ta2szzWVlZZmP2Z8reKxSU1PNswkJCUG/fQw8\nziwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABlzsiIHFxca4c99tvvzXN\nNTc3u3L7Vrm5uSG9fQw8ziwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoAB\nlzsirBw4cCDUK5jMnTs31CtggHFmCQAGfZ5ZdnV1qaSkROfOnVNnZ6eWL1+u8ePHq7i4WB6PRxMm\nTNDGjRsVEUFzATzY+oxlbW2t4uLitHXrVl2+fFnz5s3TY489psLCQj355JN66623dOjQIaWnpw/U\nvgAQEn2eEs6cOVOrVq2SJDmOI6/Xq+bmZqWmpkqSZsyYofr6eve3BIAQ6zOWsbGx8vl88vv9Wrly\npQoLC+U4jjweT+/fX716dUAWBYBQuucPG8+fP6/c3FxlZmZqzpw5t/x8sr29XUOHDnV1QQAIB33G\nsq2tTfn5+SoqKlJWVpYkadKkSTpy5Igkqa6uTikpKe5vCQAh1mcsd+zYoStXrqiqqko5OTnKyclR\nYWGhKisrtXDhQnV1dSkjI2OgdgWAkOnz1fDS0lKVlpbe8f09e/a4thAAhCOu4IHrzpw5Y5794osv\nTHOO45iP2Z/Z559/3jQ3bNgw8zHxYODd5ABgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAg\nlgBgQCwBwIDLHeG6zz//3Dx76dIl09zN36kabE8//bQrx8Xgx5klABgQSwAwIJYAYEAsAcCAWAKA\nAbEEAANiCQAGxBIADIglABgQSwAw4HJH4B+Sk5NDvQLCFGeWAGBALAHAgFgCgAGxBAADYgkABsQS\nAAyIJQAYEEsAMCCWAGDAFTx44D300EPm2Weffda9RTCocWYJAAbEEgAMiCUAGBBLADAglgBgQCwB\nwIBYAoABsQQAA2IJAAbEEgAMuNwRrlu0aJF5tr6+3jT36aefmo+5bt068+ywYcPMs/hv4cwSAAz6\nPLPs6upSSUmJzp07p87OTi1fvlwjR47U0qVLNXbsWEnS4sWLNXv27IHYFQBCps9Y1tbWKi4uTlu3\nbtXly5c1b948rVixQnl5ecrPzx+oHQEg5PqM5cyZM5WRkSFJchxHXq9XTU1NOnXqlA4dOqTExESV\nlJTI5/MNyLIAECp9/swyNjZWPp9Pfr9fK1euVGFhoaZMmaK1a9equrpao0eP1vbt2wdqVwAImXu+\nwHP+/Hnl5uYqMzNTc+bMUXp6upKTkyVJ6enpamlpcX1JAAi1PmPZ1tam/Px8FRUVKSsrS5JUUFCg\n48ePS5IaGho0efJk97cEgBDr82eWO3bs0JUrV1RVVaWqqipJUnFxsSoqKhQVFaXhw4errKxsQBYF\ngFDqM5alpaUqLS294/t79+51bSEACEe8KR0ADLjcEa7rzyWEe/bsCeocECycWQKAAbEEAANiCQAG\nxBIADIglABgQSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKA\nAbEEAANiCQAGrn8GT3d3tyTpwoULbt8UAATsZqNuNut2rseytbVVkpSdne32TQHAfWttbVViYuId\n3/c4juO4ecMdHR1qampSfHy8vF6vmzcFAAHr7u5Wa2urkpOTFRMTc8ffux5LAHgQ8AIPABgQSwAw\nIJYAYEAsAcDA9bcO3a6np0ebNm3SyZMnFR0drfLy8ru+TD8YzZ8/Xz6fT5KUkJCgzZs3h3ijwB07\ndkzbtm3T7t27dfr0aRUXF8vj8WjChAnauHGjIiIG37+z/7xPLS0tWrp0qcaOHStJWrx4sWbPnh3a\nBfupq6tLJSUlOnfunDo7O7V8+XKNHz9+UD9Wd7tPI0eODI/HyhlgX3/9tbNu3TrHcRznxx9/dJYt\nWzbQK7iio6PDyczMDPUaQfHBBx84L774orNgwQLHcRxn6dKlzg8//OA4juNs2LDB+eabb0K5XkBu\nv081NTXOrl27QrzV/dm/f79TXl7uOI7j/Pnnn84zzzwz6B+ru92ncHmsBvyfnKNHjyotLU2SNHXq\nVDU1NQ30Cq44ceKErl27pvz8fOXm5qqxsTHUKwVszJgxqqys7P26ublZqampkqQZM2aovr4+VKsF\n7Pb71NTUpMOHDys7O1slJSXy+/0h3C4wM2fO1KpVqyRJjuPI6/UO+sfqbvcpXB6rAY+l3+/vfaoq\nSV6vVzdu3BjoNYIuJiZGBQUF2rVrl95++22tWbNm0N6vjIwMRUb+/RMax3Hk8XgkSbGxsbp69Wqo\nVgvY7fdpypQpWrt2raqrqzV69Ght3749hNsFJjY2Vj6fT36/XytXrlRhYeGgf6zudp/C5bEa8Fj6\nfD61t7f3ft3T03PL/8SDVVJSkubOnSuPx6OkpCTFxcX1Xuo52P3zZ17t7e0aOnRoCLcJjvT0dCUn\nJ/f+uaWlJcQbBeb8+fPKzc1VZmam5syZ80A8Vrffp3B5rAY8ltOmTVNdXZ0kqbGxURMnThzoFVyx\nf/9+bdmyRZJ08eJF+f1+xcfHh3ir4Jg0aZKOHDkiSaqrq1NKSkqIN7p/BQUFOn78uCSpoaFBkydP\nDvFG/dfW1qb8/HwVFRUpKytL0uB/rO52n8LlsRrwyx1vvhr+008/yXEcVVRU6NFHHx3IFVzR2dmp\n9evX6/fff5fH49GaNWs0bdq0UK8VsLNnz2r16tWqqanRqVOntGHDBnV1dWncuHEqLy8flNf5//M+\nNTc3q6ysTFFRURo+fLjKyspu+fHQYFBeXq6vvvpK48aN6/3em2++qfLy8kH7WN3tPhUWFmrr1q0h\nf6y4NhwADAbPG7AAIISIJQAYEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABv8HrRURYgRruwwAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ffdc034780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting (accuracy 0.99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 10s - loss: 0.0309 - acc: 0.9909 - val_loss: 0.0126 - val_acc: 0.9971\n",
      "Epoch 2/100\n",
      " - 10s - loss: 0.0312 - acc: 0.9912 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 3/100\n",
      " - 10s - loss: 0.0318 - acc: 0.9908 - val_loss: 0.0127 - val_acc: 0.9974\n",
      "Epoch 4/100\n",
      " - 10s - loss: 0.0277 - acc: 0.9918 - val_loss: 0.0128 - val_acc: 0.9974\n",
      "Epoch 5/100\n",
      " - 10s - loss: 0.0302 - acc: 0.9914 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 6/100\n",
      " - 10s - loss: 0.0275 - acc: 0.9921 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 7/100\n",
      " - 10s - loss: 0.0295 - acc: 0.9919 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 8/100\n",
      " - 10s - loss: 0.0299 - acc: 0.9915 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 9/100\n",
      " - 10s - loss: 0.0299 - acc: 0.9915 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 10/100\n",
      " - 10s - loss: 0.0288 - acc: 0.9918 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 11/100\n",
      " - 10s - loss: 0.0311 - acc: 0.9909 - val_loss: 0.0131 - val_acc: 0.9974\n",
      "Epoch 12/100\n",
      " - 10s - loss: 0.0303 - acc: 0.9915 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 13/100\n",
      " - 10s - loss: 0.0284 - acc: 0.9911 - val_loss: 0.0131 - val_acc: 0.9974\n",
      "Epoch 14/100\n",
      " - 10s - loss: 0.0319 - acc: 0.9913 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 15/100\n",
      " - 10s - loss: 0.0315 - acc: 0.9910 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 16/100\n",
      " - 10s - loss: 0.0318 - acc: 0.9905 - val_loss: 0.0129 - val_acc: 0.9971\n",
      "Epoch 17/100\n",
      " - 10s - loss: 0.0296 - acc: 0.9909 - val_loss: 0.0130 - val_acc: 0.9976\n",
      "Epoch 18/100\n",
      " - 10s - loss: 0.0317 - acc: 0.9915 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 19/100\n",
      " - 10s - loss: 0.0275 - acc: 0.9918 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 20/100\n",
      " - 10s - loss: 0.0294 - acc: 0.9918 - val_loss: 0.0129 - val_acc: 0.9974\n",
      "Epoch 21/100\n",
      " - 10s - loss: 0.0275 - acc: 0.9912 - val_loss: 0.0130 - val_acc: 0.9974\n",
      "Epoch 22/100\n",
      " - 10s - loss: 0.0311 - acc: 0.9910 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 23/100\n",
      " - 10s - loss: 0.0296 - acc: 0.9917 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 24/100\n",
      " - 10s - loss: 0.0292 - acc: 0.9915 - val_loss: 0.0131 - val_acc: 0.9974\n",
      "Epoch 25/100\n",
      " - 10s - loss: 0.0308 - acc: 0.9910 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 26/100\n",
      " - 10s - loss: 0.0322 - acc: 0.9918 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 27/100\n",
      " - 10s - loss: 0.0303 - acc: 0.9913 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 28/100\n",
      " - 10s - loss: 0.0316 - acc: 0.9906 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 29/100\n",
      " - 10s - loss: 0.0296 - acc: 0.9921 - val_loss: 0.0127 - val_acc: 0.9967\n",
      "Epoch 30/100\n",
      " - 10s - loss: 0.0291 - acc: 0.9916 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 31/100\n",
      " - 10s - loss: 0.0315 - acc: 0.9910 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 32/100\n",
      " - 10s - loss: 0.0306 - acc: 0.9913 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 33/100\n",
      " - 10s - loss: 0.0286 - acc: 0.9918 - val_loss: 0.0130 - val_acc: 0.9969\n",
      "Epoch 34/100\n",
      " - 10s - loss: 0.0330 - acc: 0.9907 - val_loss: 0.0128 - val_acc: 0.9974\n",
      "Epoch 35/100\n",
      " - 10s - loss: 0.0298 - acc: 0.9908 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 36/100\n",
      " - 10s - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 37/100\n",
      " - 10s - loss: 0.0278 - acc: 0.9919 - val_loss: 0.0129 - val_acc: 0.9967\n",
      "Epoch 38/100\n",
      " - 10s - loss: 0.0324 - acc: 0.9904 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 39/100\n",
      " - 10s - loss: 0.0306 - acc: 0.9909 - val_loss: 0.0132 - val_acc: 0.9969\n",
      "Epoch 40/100\n",
      " - 10s - loss: 0.0290 - acc: 0.9922 - val_loss: 0.0128 - val_acc: 0.9969\n",
      "Epoch 41/100\n",
      " - 10s - loss: 0.0308 - acc: 0.9908 - val_loss: 0.0126 - val_acc: 0.9967\n",
      "Epoch 42/100\n",
      " - 10s - loss: 0.0286 - acc: 0.9911 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 43/100\n",
      " - 10s - loss: 0.0302 - acc: 0.9916 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 44/100\n",
      " - 10s - loss: 0.0315 - acc: 0.9908 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 45/100\n",
      " - 10s - loss: 0.0295 - acc: 0.9909 - val_loss: 0.0128 - val_acc: 0.9971\n",
      "Epoch 46/100\n",
      " - 10s - loss: 0.0304 - acc: 0.9913 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 47/100\n",
      " - 10s - loss: 0.0325 - acc: 0.9903 - val_loss: 0.0130 - val_acc: 0.9969\n",
      "Epoch 48/100\n",
      " - 10s - loss: 0.0318 - acc: 0.9914 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 49/100\n",
      " - 10s - loss: 0.0303 - acc: 0.9907 - val_loss: 0.0129 - val_acc: 0.9971\n",
      "Epoch 50/100\n",
      " - 10s - loss: 0.0288 - acc: 0.9916 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 51/100\n",
      " - 10s - loss: 0.0278 - acc: 0.9917 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 52/100\n",
      " - 10s - loss: 0.0323 - acc: 0.9903 - val_loss: 0.0131 - val_acc: 0.9967\n",
      "Epoch 53/100\n",
      " - 10s - loss: 0.0303 - acc: 0.9913 - val_loss: 0.0130 - val_acc: 0.9971\n",
      "Epoch 54/100\n",
      " - 10s - loss: 0.0312 - acc: 0.9908 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "Epoch 55/100\n",
      " - 10s - loss: 0.0291 - acc: 0.9913 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 56/100\n",
      " - 10s - loss: 0.0276 - acc: 0.9918 - val_loss: 0.0131 - val_acc: 0.9969\n",
      "Epoch 57/100\n",
      " - 10s - loss: 0.0324 - acc: 0.9901 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 58/100\n",
      " - 10s - loss: 0.0296 - acc: 0.9914 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 59/100\n",
      " - 10s - loss: 0.0312 - acc: 0.9915 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 60/100\n",
      " - 10s - loss: 0.0277 - acc: 0.9915 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 61/100\n",
      " - 10s - loss: 0.0307 - acc: 0.9908 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 62/100\n",
      " - 10s - loss: 0.0312 - acc: 0.9909 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 63/100\n",
      " - 10s - loss: 0.0336 - acc: 0.9903 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 64/100\n",
      " - 10s - loss: 0.0302 - acc: 0.9914 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 65/100\n",
      " - 10s - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "Epoch 66/100\n",
      " - 10s - loss: 0.0293 - acc: 0.9912 - val_loss: 0.0128 - val_acc: 0.9971\n",
      "Epoch 67/100\n",
      " - 10s - loss: 0.0330 - acc: 0.9906 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 68/100\n",
      " - 10s - loss: 0.0287 - acc: 0.9914 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 69/100\n",
      " - 10s - loss: 0.0328 - acc: 0.9910 - val_loss: 0.0138 - val_acc: 0.9969\n",
      "Epoch 70/100\n",
      " - 10s - loss: 0.0290 - acc: 0.9916 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 71/100\n",
      " - 10s - loss: 0.0274 - acc: 0.9919 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 72/100\n",
      " - 10s - loss: 0.0305 - acc: 0.9917 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 73/100\n",
      " - 10s - loss: 0.0316 - acc: 0.9911 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 74/100\n",
      " - 10s - loss: 0.0312 - acc: 0.9907 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 75/100\n",
      " - 10s - loss: 0.0295 - acc: 0.9914 - val_loss: 0.0136 - val_acc: 0.9969\n",
      "Epoch 76/100\n",
      " - 10s - loss: 0.0294 - acc: 0.9910 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 77/100\n",
      " - 10s - loss: 0.0313 - acc: 0.9909 - val_loss: 0.0143 - val_acc: 0.9967\n",
      "Epoch 78/100\n",
      " - 10s - loss: 0.0302 - acc: 0.9916 - val_loss: 0.0136 - val_acc: 0.9967\n",
      "Epoch 79/100\n",
      " - 10s - loss: 0.0330 - acc: 0.9911 - val_loss: 0.0139 - val_acc: 0.9967\n",
      "Epoch 80/100\n",
      " - 10s - loss: 0.0308 - acc: 0.9908 - val_loss: 0.0137 - val_acc: 0.9967\n",
      "Epoch 81/100\n",
      " - 10s - loss: 0.0293 - acc: 0.9916 - val_loss: 0.0139 - val_acc: 0.9964\n",
      "Epoch 82/100\n",
      " - 10s - loss: 0.0279 - acc: 0.9918 - val_loss: 0.0135 - val_acc: 0.9967\n",
      "Epoch 83/100\n",
      " - 9s - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0132 - val_acc: 0.9967\n",
      "Epoch 84/100\n",
      " - 10s - loss: 0.0296 - acc: 0.9909 - val_loss: 0.0133 - val_acc: 0.9969\n",
      "Epoch 85/100\n",
      " - 10s - loss: 0.0296 - acc: 0.9920 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 86/100\n",
      " - 10s - loss: 0.0311 - acc: 0.9911 - val_loss: 0.0139 - val_acc: 0.9964\n",
      "Epoch 87/100\n",
      " - 10s - loss: 0.0321 - acc: 0.9909 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "Epoch 88/100\n",
      " - 10s - loss: 0.0329 - acc: 0.9906 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "Epoch 89/100\n",
      " - 10s - loss: 0.0331 - acc: 0.9907 - val_loss: 0.0141 - val_acc: 0.9967\n",
      "Epoch 90/100\n",
      " - 10s - loss: 0.0319 - acc: 0.9905 - val_loss: 0.0144 - val_acc: 0.9964\n",
      "Epoch 91/100\n",
      " - 10s - loss: 0.0289 - acc: 0.9915 - val_loss: 0.0146 - val_acc: 0.9967\n",
      "Epoch 92/100\n",
      " - 10s - loss: 0.0304 - acc: 0.9915 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 93/100\n",
      " - 10s - loss: 0.0291 - acc: 0.9911 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 94/100\n",
      " - 10s - loss: 0.0289 - acc: 0.9914 - val_loss: 0.0140 - val_acc: 0.9967\n",
      "Epoch 95/100\n",
      " - 10s - loss: 0.0315 - acc: 0.9911 - val_loss: 0.0145 - val_acc: 0.9967\n",
      "Epoch 96/100\n",
      " - 10s - loss: 0.0301 - acc: 0.9910 - val_loss: 0.0144 - val_acc: 0.9969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 10s - loss: 0.0301 - acc: 0.9913 - val_loss: 0.0139 - val_acc: 0.9967\n",
      "Epoch 98/100\n",
      " - 10s - loss: 0.0318 - acc: 0.9905 - val_loss: 0.0139 - val_acc: 0.9967\n",
      "Epoch 99/100\n",
      " - 10s - loss: 0.0301 - acc: 0.9912 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 100/100\n",
      " - 10s - loss: 0.0294 - acc: 0.9912 - val_loss: 0.0137 - val_acc: 0.9964\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv('sub1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
